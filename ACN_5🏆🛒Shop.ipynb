{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ACN_5üèÜüõíShop.ipynb","provenance":[{"file_id":"1ILU6ck5KFFiMknBkGw9nvinGUdOx7u07","timestamp":1657387796872},{"file_id":"1U0T191g7R9hp8LMDHlLnbSfRZVfpPxcI","timestamp":1656990366477}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#from google.colab import drive; drive.mount('/content/drive')   # OK to enable, if kaggle.json is stored in Google Drive"],"metadata":{"id":"qrogZ_8bD9tZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657386204769,"user_tz":240,"elapsed":474071,"user":{"displayName":"Antoine Nguyen","userId":"04950359765811679258"}},"outputId":"e757845a-ffd4-4484-a5eb-6923855138c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d8XoC8VqBXGs","executionInfo":{"status":"ok","timestamp":1657386211118,"user_tz":240,"elapsed":6358,"user":{"displayName":"Antoine Nguyen","userId":"04950359765811679258"}},"outputId":"a9cf3cc5-4115-4a6a-d539-fc6adba2b1f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["cp: cannot stat 'kaggle.json': No such file or directory\n","- competition is now set to: 22122shop\n","100% 9.98M/9.98M [00:00<00:00, 73.8MB/s]\n","Using competition: 22122shop\n"," teamId  teamName                                             submissionDate       score    \n","-------  ---------------------------------------------------  -------------------  -------  \n","8249741  IB-Valhalla- Adshead,Lukianov,Odnakov                2022-03-06 18:47:06  0.99140  \n","8857973  Samuel Nathanson                                     2022-07-09 00:34:54  0.98832  \n","8853383  Robbie Cahill                                        2022-07-08 04:10:49  0.98008  \n","8250279  JF-BigSpenders-Merran,Hogge                          2022-03-06 22:07:24  0.97396  \n","8228358  JA-Shopaholics-Brodsky,Rumman,Givre                  2022-03-06 19:29:55  0.97264  \n","8205432  JE-TBD-Mendola,Natali                                2022-03-07 04:27:19  0.97152  \n","8235054  JC-TheCashCows-Hernandez-Khan                        2022-03-06 04:40:33  0.96092  \n","8263654  DG-WeDontLikeR-Astanina,Ivanova,Korzun               2022-03-06 20:53:38  0.96092  \n","8262324  DD-FKA-Fayzulina,Kokin,Alekseev                      2022-03-07 18:27:29  0.95764  \n","8246869  JB-TheTwoMusketeers-Lee,Li                           2022-03-06 02:46:46  0.94968  \n","8258634  IA-ApplePie-Ivanushkina, Argunov, Grigorenko         2022-03-06 13:33:30  0.94540  \n","8857547  David Na                                             2022-07-09 04:13:03  0.91884  \n","8235202  JG-TheBuyGuys-Barrett-Packard                        2022-03-07 01:12:13  0.90344  \n","8849969  Mo Samman                                            2022-07-09 01:31:15  0.86096  \n","8235220  JH-Shoppers-Dinh,Hu                                  2022-03-06 03:38:53  0.85540  \n","8853663  Yungjun Yoo                                          2022-07-09 03:27:07  0.85252  \n","8862506  Rohit Bollineni                                      2022-07-09 00:00:51  0.84956  \n","8854218  AntoineN1                                            2022-07-09 04:22:14  0.84500  \n","8858317  arice24                                              2022-07-06 04:50:53  0.82592  \n","8258111  JD-CostcoForLyfe-Corson,Katsaros                     2022-03-07 03:04:18  0.82476  \n","8257288  DE-Dust_2-Vasilyev, Novitskiy, Kobylkin              2022-03-07 15:26:00  0.82244  \n","8259340  DO-DoPizza-Alyakaev,Ushakov,Karhca                   2022-03-07 22:01:02  0.82120  \n","8849664  Mauricio Acosta                                      2022-07-08 23:54:42  0.81996  \n","8261824  DL-Peace-Xu, Yangirov, Veips                         2022-03-06 19:20:17  0.81988  \n","8852008  carlosrivasJHU                                       2022-07-08 15:12:59  0.81920  \n","8257230  DM-FrozenYogurts-Malchenko, Baminiwatte, Goncharov   2022-03-06 20:26:41  0.81664  \n","8257304  DF-MPK-Mozharov, Parakal, Kolobaev                   2022-03-06 19:01:46  0.81628  \n","8261357  DJ-EBAN-Fishman,Zotov                                2022-03-06 12:08:27  0.81396  \n","8268328  DR-March22-Dzhkha,Kotukhov,Babayan                   2022-03-07 16:06:20  0.81192  \n","8263842  DQ ‚Äì Solo By Mariasha ‚Äì Rybnikova, Lakeev, Dittrich  2022-03-06 20:38:40  0.81188  \n","8260934  DA-ThermoBobri-Babakekhyan, Ignatyev, Sharara        2022-03-06 20:10:01  0.81172  \n","8263825  DS-HTTPS-Bashminova, Rutsinsky, Kurbatov             2022-03-06 20:42:30  0.81140  \n","8258564  DH-AFK-Fakhretdinov, Gyursoy, Vasyutin               2022-03-08 17:30:12  0.81140  \n","8291251  DC-DC-Kukarkins-Omarova-Lanin                        2022-03-07 14:52:03  0.81028  \n","8263593  7T-NDA-Sokolov,Stepin,Zaytsev                        2022-03-07 14:04:46  0.80508  \n","8854024  üêß05üõí 5-Retro Lightning-Samman,Cui                    2022-07-08 12:21:01  0.80504  \n","8258739  DI-Egorov Did It Solo-Egorov,Korotonozhkin,Madhavan  2022-03-05 19:06:58  0.80492  \n","8262798  Anton Ivanov                                         2022-03-06 17:18:28  0.80428  \n","8194283  üõíHSE baseline                                        2022-02-21 04:44:25  0.80392  \n","8261551  DT-p1|3-Zaitsev, Stepin, Sokolov                     2022-03-07 08:39:52  0.80392  \n","8274914  DN-O-Poletaev,Nikitin,Yakunina                       2022-03-08 19:34:32  0.80380  \n","8193952  üõíJHU baseline                                        2022-02-21 03:28:25  0.79960  \n","8262747  D8-Mignongs-Akopyan,Ruban,Dryagin                    2022-03-06 21:00:35  0.79440  \n"]}],"source":["!pip -q install --upgrade --force-reinstall --no-deps kaggle > log  # upgrade kaggle package (to avoid a warning)\n","!mkdir -p ~/.kaggle                               # .kaggle folder must contain kaggle.json for kaggle executable to properly authenticate you to Kaggle.com\n","#!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json >log  # First, download kaggle.json from kaggle.com (in Account page) and place it in the root of mounted Google Drive\n","!cp kaggle.json ~/.kaggle/kaggle.json > log       # Alternative location of kaggle.json (without a connection to Google Drive)\n","!chmod 600 ~/.kaggle/kaggle.json                  # give only the owner full read/write access to kaggle.json\n","!kaggle config set -n competition -v 22122shop    # set the competition context for the next few kaggle API calls. !kaggle config view - shows current settings\n","!kaggle competitions download >> log              # download competition dataset as a zip file\n","!unzip -o *.zip >> log                            # Kaggle dataset is copied as a single file and needs to be unzipped.\n","!kaggle competitions leaderboard --show           # print public leaderboard"]},{"cell_type":"code","source":["!pip -q install -U tensorflow_addons > log"],"metadata":{"id":"5Iie9fjWKwpV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","%%capture\n","%reset -f\n","from IPython.core.interactiveshell import InteractiveShell as IS; IS.ast_node_interactivity = \"all\" \n","import numpy as np, pandas as pd, time, matplotlib.pyplot as plt, seaborn as sns, tensorflow_addons as tfa\n","from sklearn.preprocessing import PolynomialFeatures\n","import tensorflow as tf, tensorflow.keras as keras\n","from keras.layers import Flatten, Dense\n","ToCSV = lambda df, fname: df.round(2).to_csv(f'{fname}.csv', index_label='id') # rounds values to 2 decimals\n","\n","class Timer():\n","  def __init__(self, lim:'RunTimeLimit'=60): self.t0, self.lim, _ = time.time(), lim, print(f'‚è≥ started. You have {lim} sec. Good luck!')\n","  def ShowTime(self):\n","    msg = f'Runtime is {time.time()-self.t0:.0f} sec'\n","    print(f'\\033[91m\\033[1m' + msg + f' > {self.lim} sec limit!!!\\033[0m' if (time.time()-self.t0-1) > self.lim else msg)\n","\n","np.set_printoptions(linewidth=100, precision=2, edgeitems=2, suppress=True)\n","pd.set_option('max_columns', 20, 'precision', 2, 'display.max_rows', 4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7CyC-JlZFga1","executionInfo":{"status":"ok","timestamp":1657389578503,"user_tz":-120,"elapsed":4673,"user":{"displayName":"Carlos Rivas","userId":"14593089985619551016"}},"outputId":"e65290e5-61c0-4ab8-db55-37fbfe309505"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 3.69 s, sys: 453 ms, total: 4.14 s\n","Wall time: 4.5 s\n"]}]},{"cell_type":"code","source":["df = pd.read_csv('XY_Shop.csv'); df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"X00bQLb5FpxU","executionInfo":{"status":"ok","timestamp":1657389579842,"user_tz":-120,"elapsed":1353,"user":{"displayName":"Carlos Rivas","userId":"14593089985619551016"}},"outputId":"b8057318-0100-4947-e6de-aa8d7322d380"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Adm  AdmDur  Inf  InfDur  Prd   PrdDur     BncRt  ExtRt  PgVal  SpclDay  \\\n","0     0    0.00    0     0.0   18   132.99  3.82e-02   0.05   0.00      0.0   \n","1     1    0.00    0     0.0   37  1150.20  1.25e-03   0.03   0.00      0.0   \n","..  ...     ...  ...     ...  ...      ...       ...    ...    ...      ...   \n","3     3  263.68    0     0.0   24   749.14  4.47e-03   0.02  14.58      0.0   \n","4     0    0.00    0     0.0    3   136.41  0.00e+00   0.07   0.00      0.0   \n","\n","    Mo  OS  Bsr  Rgn  TfcTp  VstTp  Wkd  Rev  \n","0    4   3    1    1      2      0    1  NaN  \n","1   11   2    2    4      2      0    1  NaN  \n","..  ..  ..  ...  ...    ...    ...  ...  ...  \n","3    7   2    2    2      1      0    1  NaN  \n","4   12   1    1    3      3      1    0  NaN  \n","\n","[5 rows x 18 columns]"],"text/html":["\n","  <div id=\"df-0d288929-8a52-4420-b660-974f4211a591\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Adm</th>\n","      <th>AdmDur</th>\n","      <th>Inf</th>\n","      <th>InfDur</th>\n","      <th>Prd</th>\n","      <th>PrdDur</th>\n","      <th>BncRt</th>\n","      <th>ExtRt</th>\n","      <th>PgVal</th>\n","      <th>SpclDay</th>\n","      <th>Mo</th>\n","      <th>OS</th>\n","      <th>Bsr</th>\n","      <th>Rgn</th>\n","      <th>TfcTp</th>\n","      <th>VstTp</th>\n","      <th>Wkd</th>\n","      <th>Rev</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.00</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>18</td>\n","      <td>132.99</td>\n","      <td>3.82e-02</td>\n","      <td>0.05</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.00</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>37</td>\n","      <td>1150.20</td>\n","      <td>1.25e-03</td>\n","      <td>0.03</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>11</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>263.68</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>24</td>\n","      <td>749.14</td>\n","      <td>4.47e-03</td>\n","      <td>0.02</td>\n","      <td>14.58</td>\n","      <td>0.0</td>\n","      <td>7</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0.00</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>136.41</td>\n","      <td>0.00e+00</td>\n","      <td>0.07</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>12</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows √ó 18 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d288929-8a52-4420-b660-974f4211a591')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0d288929-8a52-4420-b660-974f4211a591 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0d288929-8a52-4420-b660-974f4211a591');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["vX = df.query('Rev!=Rev').drop('Rev', axis=1)  # slice a test sample\n","tXY = df.query('Rev==Rev')                     # slice training sample\n","tX, tY = tXY.drop('Rev', axis=1), tXY.Rev      # split into training I/O\n","NumFeatures = list(tX.select_dtypes(np.number).columns)"],"metadata":{"id":"f7OuVizOFsFF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#tmr = Timer()"],"metadata":{"id":"z4_C58bbHuja"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<hr color=red>\n","\n","<font size=5>‚è≥</font> <strong><font color=orange size=5>Your Code, Documentation, Ideas and Timer - All Start Here...</font></strong>\n","\n","**Student's Section** (between ‚è≥ symbols): add your code and documentation here."],"metadata":{"id":"3NcTKbw3KhAn"}},{"cell_type":"markdown","metadata":{"id":"OpyLNt3god0c"},"source":["## **Task 1. Preprocessing Pipeline**\n"," \n","Explain elements of your preprocessing pipeline i.e. feature engineering, subsampling, clustering, dimensionality reduction, etc. \n","1. Why did you choose these elements? (Something in EDA, prior experience,...? Btw, EDA is not required)\n","1. How do you evaluate the effectiveness of these elements? \n","1. What else have you tried that worked or didn't? "]},{"cell_type":"markdown","metadata":{"id":"30xYIFXAnaPE"},"source":["1. Observing the eda, it is apparent that the target class has a severe class imbalance. There are almost 3x the amount of the 0 class compared to that of the 1 class. Additionally observing the eda, some features such as \"browser\" and \"OS\" may not contribute much towards the dataset and can possibly dropped.\n","\n","\n","2. The effectiveness of these elements were evaluated through the resulting f1 score obtained after training the model. The scores were checked after each time an element was added or removed to check their effectiveness on raising the f1 score or training/validation accuracy. Additionally, observing the live scores get printed on screen from fitting the model to the data allowed us to quickly observe if a certain element we were testing caused the model to severely degrade. \n","\n","\n","3. One of our first attempts was just to use the floating point columns how the base starter code had. This however, never brought our score above 82%. We settled on using the full feature set which allowed us to obtain higher scores. We noticed that there were some features/classes that were imbalanced and used random oversampling and SMOTE to generate new synthetic data in attempts to create more balance in the dataset. The result of using these methods on the dataset caused the validation accuracy to stall around 65% throughout the training iterations. We then tried to create more features through polynomial features at a degree of 2-3. We noticed that there were marginal increases in accuracy if any and that it only contributed to more compute time. Using StandardScaler provided the greatest training/validation accuracy at almost 90% however when tested with the f1 score, significantly overfitted and resulted in scores around 77%. Using PCA we found to give us the greatest increase in accuracy and f1 scores among the other preprocessing steps mentioned. It is known to use standardization before PCA however, when we tried this, it resulted in poor performance. "]},{"cell_type":"markdown","metadata":{"id":"KGJRwzqHob4o"},"source":["## **Task 2. Modeling Approach**\n","Explain your modeling approach, i.e. ideas you tried and why you thought they would be helpful. \n","\n","1. How did these decisions guide you in modeling?\n","1. How do you evaluate the effectiveness of these elements? \n","1. What else have you tried that worked or didn't? "]},{"cell_type":"markdown","metadata":{"id":"zi6ZjgtWnb58"},"source":["1. It is well known that deeper networks provide for better results. We saw this almost immediately experimenting with the effects of adding more layers to the base kaggle notebook and observing its effects on the accuracy obtained. Also experimenting with different activiation and optimizers such as \"selu/relu\" and \"RMSprop/Adam\" and their resulting accuracies on the model. \n","\n","\n","2. Like Task 1, The effectiveness of these elements were evaluated through the resulting f1 score obtained after training the model. The scores were checked after each time an element was added or removed to check their effectiveness on raising the f1 score or training/validation accuracy. Additionally, observing the live scores get printed on screen from fitting the model to the data allowed us to quickly observe if a certain element we were testing caused the model to severely degrade.\n","\n","\n","3. We tried changing the amount of Dense layers as well as the number of units within each Dense layer. We saw that increasing the amount of Dense layers improves the accuracies obtained up to a certain point before it begins to plateau. Likewise, increasing the size of the units generally improved the accuracy but increasing the units to larger units caused a longer training duration. Another parameter we experimented with and saw some success with was changing the batch size and learning rate. We saw that increasing the batch size while decreasing the learning rate created a decent tradeoff as increasing the batch size causes a smaller amount of data to be processed per epoch, improving compute time and decreasing the learning causes slower convergence. Changing the number of epochs to something greater than 50 allowed us to obtain scores higher than 82 while still maintaining the 60s window. "]},{"cell_type":"markdown","source":["## Other Models and Their Resulting Accuracies"],"metadata":{"id":"lLxGkXZwSkk9"}},{"cell_type":"markdown","source":["## EDA"],"metadata":{"id":"yRfVHHIV9nvn"}},{"cell_type":"markdown","source":["Class imbalance with the target variable"],"metadata":{"id":"kzJbXImZ9vH2"}},{"cell_type":"markdown","source":["Model 1"],"metadata":{"id":"Ases8Yv8TF_C"}},{"cell_type":"code","source":["# vX = df.query('Rev!=Rev').drop('Rev', axis=1)  # slice a test sample\n","# tXY = df.query('Rev==Rev')                     # slice training sample\n","# tX, tY = tXY.drop('Rev', axis=1), tXY.Rev      # split into training I/O\n","# NumFeatures = list(tX.select_dtypes(include='float').columns)\n","# print('Numeric features: ', NumFeatures)       # numeric/quantitative feature names\n","\n","# train_data = tX.copy()\n","\n","\n","# train_data = train_data.drop(columns = ['Bsr','Rgn','TfcTp'],axis=1)\n","# train_data\n","\n","\n","# from sklearn import preprocessing\n","# from sklearn.preprocessing import StandardScaler\n","# scaler = StandardScaler().fit(train_data.values)\n","\n","# scaledf = scaler.transform(train_data.values) #training dataset\n","# scaled_training = pd.DataFrame(scaledf, index=train_data.index, columns=train_data.columns)\n","# scaled_training\n","\n","\n","# tX_in = scaled_training\n","# tY_in = tY\n","\n","# m = keras.Sequential([\n","#     keras.layers.Dense(70, activation=tf.nn.relu,\n","#                      input_shape=[tX_in.shape[1]]),\n","#     #keras.layers.Dropout(0.25),\n","#     keras.layers.Dense(70, activation=tf.nn.relu),\n","#     #keras.layers.Dropout(0.25),\n","#     keras.layers.Dense(70, activation=tf.nn.relu),\n","#     keras.layers.Dense(70, activation=tf.nn.relu),\n","#     keras.layers.Dense(70, activation=tf.nn.relu),\n","# #     keras.layers.Dense(70, activation=tf.nn.relu),\n","#     #keras.layers.Dropout(0.25),\n","# #     keras.layers.Flatten(),\n","# #     keras.layers.Dense(10, activation=tf.nn.relu),\n","#     keras.layers.Flatten(),\n","#     keras.layers.Dense(10, activation=tf.nn.relu),\n","#     keras.layers.Dense(10, activation=tf.nn.relu),\n","\n","#     keras.layers.Dense(1, activation= \"sigmoid\")\n","#   ])\n","\n","# m.summary()\n","# m.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n","# hist = m.fit(tX_in, tY_in, epochs=10, validation_split=0.3, batch_size=32)"],"metadata":{"id":"5C1-uIqUSu_A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["accuracy: 0.9091 - val_loss: 0.2453 - val_accuracy: 0.9065"],"metadata":{"id":"DSCvIxoLTCsq"}},{"cell_type":"markdown","source":["Model 2"],"metadata":{"id":"pepzpjDKTLp5"}},{"cell_type":"code","source":["# vX = df.query('Rev!=Rev').drop('Rev', axis=1)  # slice a test sample\n","# tXY = df.query('Rev==Rev')                     # slice training sample\n","# tX, tY = tXY.drop('Rev', axis=1), tXY.Rev      # split into training I/O\n","# NumFeatures = list(tX.select_dtypes(np.number).columns)\n","# print('Numeric features: ', NumFeatures)     \n","\n","# train_data = tX.copy()\n","# train_data = train_data.drop(columns = ['Inf','PgVal'],axis=1)\n","\n","# from sklearn import preprocessing\n","# from sklearn.preprocessing import StandardScaler\n","# scaler = StandardScaler().fit(train_data.values)\n","\n","# scaledf = scaler.transform(train_data.values) #training dataset\n","# scaled_training = pd.DataFrame(scaledf, index=train_data.index, columns=train_data.columns)\n","# scaled_training\n","\n","# tX_in = scaled_training\n","# tY_in = tY_in\n","\n","# m = keras.Sequential([\n","#     keras.layers.Dense(70, activation=tf.nn.relu,\n","#                      input_shape=[tX_in.shape[1]]),\n","#     keras.layers.Dropout(0.25),\n","#     keras.layers.Dense(70, activation=tf.nn.relu),\n","#     keras.layers.Dropout(0.25),\n","#     keras.layers.Dense(70, activation=tf.nn.relu),\n","#     keras.layers.Dense(70, activation=tf.nn.relu),\n","#     keras.layers.Dense(70, activation=tf.nn.relu),\n","#     keras.layers.Dropout(0.25),\n","# #     keras.layers.Flatten(),\n","# #     keras.layers.Dense(10, activation=tf.nn.relu),\n","#     keras.layers.Flatten(),\n","#     keras.layers.Dense(10, activation=tf.nn.relu),\n","#     keras.layers.Dense(10, activation=tf.nn.relu),\n","#     keras.layers.Dense(10, activation=tf.nn.relu),\n","#     keras.layers.Dense(1, activation= \"sigmoid\")\n","#   ])\n","\n","# m.summary()\n","# m.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n","# hist = m.fit(tX_in, tY_in, epochs=20, validation_split=0.3, batch_size=32)\n","\n"],"metadata":{"id":"aafYuG7DSu8U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["loss: 0.1885 - accuracy: 0.9210 - val_loss: 0.1994 - val_accuracy: 0.9199"],"metadata":{"id":"8MaYljM9TsKR"}},{"cell_type":"markdown","source":["Model 3"],"metadata":{"id":"Z5xf9W-OT6VW"}},{"cell_type":"code","source":["# vX = df.query('Rev!=Rev').drop('Rev', axis=1)  # slice a test sample\n","# tXY = df.query('Rev==Rev')                     # slice training sample\n","# tX, tY = tXY.drop('Rev', axis=1), tXY.Rev      # split into training I/O\n","# NumFeatures = list(tX.select_dtypes(include='float').columns)\n","# print('Numeric features: ', NumFeatures)   \n","\n","# train_data = tX.copy()\n","\n","# from sklearn import preprocessing\n","# from sklearn.preprocessing import StandardScaler\n","# scaler = StandardScaler().fit(train_data.values)\n","\n","# scaledf = scaler.transform(train_data.values) #training dataset\n","# scaled_training = pd.DataFrame(scaledf, index=train_data.index, columns=train_data.columns)\n","# scaled_training\n","\n","\n","# from sklearn.decomposition import PCA\n","# pca = PCA(10)\n","# pca.fit(scaled_training)\n","# original_variance = pca.explained_variance_ratio_\n","\n","# pca_data = pca.transform(scaled_training)\n","\n","# tX_in = pca_data\n","# tY_in = tY\n","\n","# m = keras.Sequential([ keras.layers.Dense(60, activation=tf.nn.relu, input_shape=[tX_in.shape[1]]), \n","                                          \n","#   #keras.layers.Dropout(0.25), \n","#   keras.layers.Dense(60, activation=tf.nn.relu, input_shape=[tX_in.shape[1]]), \n","                                          \n","#   #keras.layers.Dropout(0.25), \n","# keras.layers.Dense(60, activation=tf.nn.relu, input_shape=[tX_in.shape[1]]), \n","# keras.layers.Dense(32,activation=tf.nn.relu), \n","# #\n","# keras.layers.Dense(16,activation=tf.nn.relu), #kernel_regularizer=keras.regularizers.l2(0.1), ), \n","# keras.layers.Dense(1, activation= \"sigmoid\") ])\n","\n","\n","# m.summary()\n","# m.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n","# hist = m.fit(tX_in, tY_in, epochs=10, validation_split=0.3, batch_size=32)\n"],"metadata":{"id":"tdmEYeBUSu5r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["loss: 0.2573 - accuracy: 0.9000 - val_loss: 0.2629 - val_accuracy: 0.8982"],"metadata":{"id":"fzy2N298UIOj"}},{"cell_type":"markdown","metadata":{"id":"YJs0jS4fIO1j"},"source":["## Final Model"]},{"cell_type":"code","source":["train_data = tX.copy()"],"metadata":{"id":"z5rC8mM_F7wN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data.shape"],"metadata":{"id":"sOmINew8F7t7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657389582356,"user_tz":-120,"elapsed":6,"user":{"displayName":"Carlos Rivas","userId":"14593089985619551016"}},"outputId":"a060db51-cb5d-4fd6-cd71-a0d42c03359a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(450000, 17)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["tX_in = train_data[NumFeatures][:50000]\n","tY_in = tXY.Rev[:50000]"],"metadata":{"id":"3aqge9ojF7qj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.decomposition import PCA\n","pca = PCA(14)\n","pca.fit(tX_in)\n","original_variance = pca.explained_variance_ratio_\n","pca_data = pca.transform(tX_in)"],"metadata":{"id":"MnUA0drnF7oO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657389583784,"user_tz":-120,"elapsed":311,"user":{"displayName":"Carlos Rivas","userId":"14593089985619551016"}},"outputId":"a5945d1e-4a41-4994-f08d-a0a25ad9f1a9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PCA(n_components=14)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":[""],"metadata":{"id":"8iY_AN7kEt98"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten\n","from tensorflow.keras.optimizers import SGD\n","from tensorflow.keras import datasets, layers, models\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras import regularizers\n","import tensorflow as tf, tensorflow.keras as keras\n","from keras.layers import Flatten, Dense\n","from tensorflow.keras.layers import BatchNormalization"],"metadata":{"id":"ILSQjo1jF7iK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tf.random.set_seed(69)   # always seed your experiments\n","Init = tf.keras.initializers.RandomNormal(seed=69)"],"metadata":{"id":"A1NTcwyYGQOK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tX_in = pca_data\n","tY_in = tY\n","\n","m = keras.Sequential([\n","    keras.layers.Dense(90, activation=tf.nn.selu,\n","                     input_shape=[tX_in.shape[1]]),\n","    \n","    keras.layers.Dense(90, activation=tf.nn.selu),\n","    keras.layers.Dense(90, activation=tf.nn.selu),\n","    # keras.layers.Dense(90, activation=tf.nn.selu),\n","    # keras.layers.Dense(90, activation=tf.nn.selu),\n","    # keras.layers.Dense(90, activation=tf.nn.selu),\n","    # keras.layers.Dense(90, activation=tf.nn.selu),\n","    # keras.layers.Dense(90, activation=tf.nn.selu),\n","    \n","    keras.layers.Flatten(),\n","    keras.layers.Dense(90, activation=tf.nn.selu),\n","    keras.layers.Dense(90, activation=tf.nn.selu),# step size = 10\n","    keras.layers.Dense(32, activation=tf.nn.selu),# step size = 6\n","\n","    keras.layers.Dense(1, activation= \"sigmoid\")\n","  ])\n","\n","\n","#### \n","# NOTE FOR CARLOS AND NAVEEN ####\n","####\n","### The code below got 84% on kaggle and is shorter runtime than the code above in google collab. Im not sure why its taking 5 mins on this collab \n","### notebook, when it only took 53 seconds on my computer to run inside a juypter notebook. Try playing with the layers and the number of epochs to adjust the time.\n","\n","\n","\n","# tX_in = pca_data\n","# tY_in = tY\n","\n","# m = keras.models.Sequential([\n","#     Flatten(input_shape=[tX_in.shape[1]], name='input'),\n","#     Dense(256, activation=\"selu\", kernel_initializer=Init),\n","    \n","#     Dense(256, activation=\"selu\", kernel_initializer=Init),\n","\n","# #     Dropout(0.3),\n","# #     BatchNormalization(),\n","#     Dense(128, activation=\"selu\", kernel_initializer=Init),\n","# #     Dropout(0.3),\n","# #     BatchNormalization(),\n","#     Dense(32, activation=\"selu\", kernel_initializer=Init),\n","\n","# #     Dropout(0.3),\n","# #     BatchNormalization(),\n","#     Dense(1, activation='sigmoid', kernel_initializer=Init, name='output')])\n","\n","#m.summary()\n","m.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])\n","hist = m.fit(tX_in, tY_in, epochs=100, validation_split=0.3, batch_size=64)\n"],"metadata":{"id":"-mfVdCP1GSVv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657389861812,"user_tz":-120,"elapsed":263900,"user":{"displayName":"Carlos Rivas","userId":"14593089985619551016"}},"outputId":"581ca390-b7fb-4125-8c69-9625af70c956"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","547/547 [==============================] - 4s 5ms/step - loss: 0.6871 - accuracy: 0.7750 - val_loss: 0.5705 - val_accuracy: 0.7907\n","Epoch 2/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.5193 - accuracy: 0.7939 - val_loss: 0.4760 - val_accuracy: 0.8020\n","Epoch 3/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.5074 - accuracy: 0.8008 - val_loss: 0.5175 - val_accuracy: 0.7828\n","Epoch 4/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.4991 - accuracy: 0.8030 - val_loss: 0.6284 - val_accuracy: 0.8058\n","Epoch 5/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.4899 - accuracy: 0.8052 - val_loss: 0.5343 - val_accuracy: 0.8059\n","Epoch 6/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.4844 - accuracy: 0.8073 - val_loss: 0.4525 - val_accuracy: 0.8109\n","Epoch 7/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.4709 - accuracy: 0.8097 - val_loss: 0.4733 - val_accuracy: 0.8074\n","Epoch 8/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.4717 - accuracy: 0.8089 - val_loss: 0.4506 - val_accuracy: 0.8119\n","Epoch 9/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.4623 - accuracy: 0.8125 - val_loss: 0.4611 - val_accuracy: 0.8096\n","Epoch 10/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.4618 - accuracy: 0.8127 - val_loss: 0.4640 - val_accuracy: 0.8142\n","Epoch 11/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.4536 - accuracy: 0.8137 - val_loss: 0.6653 - val_accuracy: 0.8107\n","Epoch 12/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.4481 - accuracy: 0.8158 - val_loss: 0.4506 - val_accuracy: 0.8124\n","Epoch 13/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.4434 - accuracy: 0.8156 - val_loss: 0.4636 - val_accuracy: 0.8138\n","Epoch 14/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.4416 - accuracy: 0.8184 - val_loss: 0.4473 - val_accuracy: 0.8109\n","Epoch 15/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.4378 - accuracy: 0.8179 - val_loss: 0.4362 - val_accuracy: 0.8153\n","Epoch 16/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.4408 - accuracy: 0.8170 - val_loss: 0.4647 - val_accuracy: 0.8110\n","Epoch 17/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.4353 - accuracy: 0.8194 - val_loss: 0.4972 - val_accuracy: 0.7867\n","Epoch 18/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.4298 - accuracy: 0.8208 - val_loss: 0.4296 - val_accuracy: 0.8193\n","Epoch 19/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.4303 - accuracy: 0.8198 - val_loss: 0.4218 - val_accuracy: 0.8175\n","Epoch 20/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.4244 - accuracy: 0.8207 - val_loss: 0.4280 - val_accuracy: 0.8171\n","Epoch 21/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.4227 - accuracy: 0.8222 - val_loss: 0.4214 - val_accuracy: 0.8193\n","Epoch 22/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.4182 - accuracy: 0.8235 - val_loss: 0.4463 - val_accuracy: 0.8167\n","Epoch 23/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.4213 - accuracy: 0.8224 - val_loss: 0.4408 - val_accuracy: 0.8167\n","Epoch 24/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.4188 - accuracy: 0.8235 - val_loss: 0.4674 - val_accuracy: 0.8039\n","Epoch 25/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.4166 - accuracy: 0.8235 - val_loss: 0.4152 - val_accuracy: 0.8194\n","Epoch 26/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.4151 - accuracy: 0.8249 - val_loss: 0.4188 - val_accuracy: 0.8179\n","Epoch 27/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.4115 - accuracy: 0.8249 - val_loss: 0.4167 - val_accuracy: 0.8167\n","Epoch 28/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.4133 - accuracy: 0.8253 - val_loss: 0.4215 - val_accuracy: 0.8191\n","Epoch 29/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.4098 - accuracy: 0.8262 - val_loss: 0.4152 - val_accuracy: 0.8175\n","Epoch 30/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.4099 - accuracy: 0.8256 - val_loss: 0.4155 - val_accuracy: 0.8171\n","Epoch 31/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.4083 - accuracy: 0.8277 - val_loss: 0.4133 - val_accuracy: 0.8155\n","Epoch 32/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.4066 - accuracy: 0.8261 - val_loss: 0.4078 - val_accuracy: 0.8221\n","Epoch 33/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.4042 - accuracy: 0.8274 - val_loss: 0.4125 - val_accuracy: 0.8213\n","Epoch 34/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.4056 - accuracy: 0.8261 - val_loss: 0.4193 - val_accuracy: 0.8217\n","Epoch 35/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.4085 - accuracy: 0.8263 - val_loss: 0.4163 - val_accuracy: 0.8173\n","Epoch 36/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.4025 - accuracy: 0.8283 - val_loss: 0.4077 - val_accuracy: 0.8213\n","Epoch 37/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.4015 - accuracy: 0.8284 - val_loss: 0.4096 - val_accuracy: 0.8201\n","Epoch 38/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.4019 - accuracy: 0.8281 - val_loss: 0.4182 - val_accuracy: 0.8229\n","Epoch 39/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.3980 - accuracy: 0.8289 - val_loss: 0.4099 - val_accuracy: 0.8232\n","Epoch 40/100\n","547/547 [==============================] - 3s 6ms/step - loss: 0.3989 - accuracy: 0.8294 - val_loss: 0.4399 - val_accuracy: 0.7951\n","Epoch 41/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3985 - accuracy: 0.8286 - val_loss: 0.4014 - val_accuracy: 0.8216\n","Epoch 42/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3953 - accuracy: 0.8296 - val_loss: 0.4065 - val_accuracy: 0.8230\n","Epoch 43/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3965 - accuracy: 0.8297 - val_loss: 0.4260 - val_accuracy: 0.8025\n","Epoch 44/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3961 - accuracy: 0.8306 - val_loss: 0.4111 - val_accuracy: 0.8207\n","Epoch 45/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3941 - accuracy: 0.8309 - val_loss: 0.4056 - val_accuracy: 0.8229\n","Epoch 46/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3946 - accuracy: 0.8307 - val_loss: 0.4044 - val_accuracy: 0.8227\n","Epoch 47/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3933 - accuracy: 0.8314 - val_loss: 0.4057 - val_accuracy: 0.8266\n","Epoch 48/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3927 - accuracy: 0.8307 - val_loss: 0.4255 - val_accuracy: 0.8090\n","Epoch 49/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3944 - accuracy: 0.8305 - val_loss: 0.4188 - val_accuracy: 0.8216\n","Epoch 50/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.3914 - accuracy: 0.8309 - val_loss: 0.4256 - val_accuracy: 0.8228\n","Epoch 51/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3888 - accuracy: 0.8326 - val_loss: 0.3990 - val_accuracy: 0.8257\n","Epoch 52/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.3873 - accuracy: 0.8332 - val_loss: 0.4179 - val_accuracy: 0.8245\n","Epoch 53/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3880 - accuracy: 0.8345 - val_loss: 0.4029 - val_accuracy: 0.8211\n","Epoch 54/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3881 - accuracy: 0.8342 - val_loss: 0.3989 - val_accuracy: 0.8227\n","Epoch 55/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3847 - accuracy: 0.8347 - val_loss: 0.4145 - val_accuracy: 0.8252\n","Epoch 56/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.3877 - accuracy: 0.8339 - val_loss: 0.4044 - val_accuracy: 0.8233\n","Epoch 57/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3845 - accuracy: 0.8359 - val_loss: 0.3989 - val_accuracy: 0.8273\n","Epoch 58/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.3849 - accuracy: 0.8357 - val_loss: 0.4111 - val_accuracy: 0.8213\n","Epoch 59/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3832 - accuracy: 0.8357 - val_loss: 0.4010 - val_accuracy: 0.8253\n","Epoch 60/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3827 - accuracy: 0.8368 - val_loss: 0.4042 - val_accuracy: 0.8261\n","Epoch 61/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.3822 - accuracy: 0.8353 - val_loss: 0.4011 - val_accuracy: 0.8259\n","Epoch 62/100\n","547/547 [==============================] - 4s 7ms/step - loss: 0.3823 - accuracy: 0.8371 - val_loss: 0.4026 - val_accuracy: 0.8265\n","Epoch 63/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.3788 - accuracy: 0.8377 - val_loss: 0.4072 - val_accuracy: 0.8267\n","Epoch 64/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.3796 - accuracy: 0.8366 - val_loss: 0.3981 - val_accuracy: 0.8266\n","Epoch 65/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.3809 - accuracy: 0.8368 - val_loss: 0.3983 - val_accuracy: 0.8238\n","Epoch 66/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.3803 - accuracy: 0.8376 - val_loss: 0.4027 - val_accuracy: 0.8261\n","Epoch 67/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.3782 - accuracy: 0.8389 - val_loss: 0.3975 - val_accuracy: 0.8289\n","Epoch 68/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.3787 - accuracy: 0.8384 - val_loss: 0.4064 - val_accuracy: 0.8248\n","Epoch 69/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3760 - accuracy: 0.8393 - val_loss: 0.4055 - val_accuracy: 0.8273\n","Epoch 70/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3749 - accuracy: 0.8396 - val_loss: 0.3948 - val_accuracy: 0.8269\n","Epoch 71/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3759 - accuracy: 0.8407 - val_loss: 0.3982 - val_accuracy: 0.8263\n","Epoch 72/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3730 - accuracy: 0.8401 - val_loss: 0.4055 - val_accuracy: 0.8287\n","Epoch 73/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3724 - accuracy: 0.8415 - val_loss: 0.3926 - val_accuracy: 0.8263\n","Epoch 74/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3721 - accuracy: 0.8418 - val_loss: 0.3925 - val_accuracy: 0.8299\n","Epoch 75/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3727 - accuracy: 0.8418 - val_loss: 0.4122 - val_accuracy: 0.8268\n","Epoch 76/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3731 - accuracy: 0.8403 - val_loss: 0.3957 - val_accuracy: 0.8301\n","Epoch 77/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.3686 - accuracy: 0.8420 - val_loss: 0.3981 - val_accuracy: 0.8266\n","Epoch 78/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.3692 - accuracy: 0.8429 - val_loss: 0.3968 - val_accuracy: 0.8271\n","Epoch 79/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3701 - accuracy: 0.8425 - val_loss: 0.3940 - val_accuracy: 0.8274\n","Epoch 80/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3681 - accuracy: 0.8435 - val_loss: 0.3962 - val_accuracy: 0.8266\n","Epoch 81/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3668 - accuracy: 0.8439 - val_loss: 0.4066 - val_accuracy: 0.8257\n","Epoch 82/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3664 - accuracy: 0.8453 - val_loss: 0.4154 - val_accuracy: 0.8271\n","Epoch 83/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3668 - accuracy: 0.8438 - val_loss: 0.3932 - val_accuracy: 0.8306\n","Epoch 84/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.3654 - accuracy: 0.8436 - val_loss: 0.3916 - val_accuracy: 0.8315\n","Epoch 85/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3650 - accuracy: 0.8446 - val_loss: 0.3978 - val_accuracy: 0.8277\n","Epoch 86/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.3642 - accuracy: 0.8451 - val_loss: 0.3903 - val_accuracy: 0.8325\n","Epoch 87/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.3626 - accuracy: 0.8463 - val_loss: 0.3960 - val_accuracy: 0.8281\n","Epoch 88/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3623 - accuracy: 0.8465 - val_loss: 0.3872 - val_accuracy: 0.8323\n","Epoch 89/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.3616 - accuracy: 0.8455 - val_loss: 0.3941 - val_accuracy: 0.8303\n","Epoch 90/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.3606 - accuracy: 0.8481 - val_loss: 0.4029 - val_accuracy: 0.8236\n","Epoch 91/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.3622 - accuracy: 0.8457 - val_loss: 0.3865 - val_accuracy: 0.8335\n","Epoch 92/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3615 - accuracy: 0.8461 - val_loss: 0.3860 - val_accuracy: 0.8338\n","Epoch 93/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3593 - accuracy: 0.8474 - val_loss: 0.3951 - val_accuracy: 0.8311\n","Epoch 94/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3589 - accuracy: 0.8485 - val_loss: 0.3935 - val_accuracy: 0.8293\n","Epoch 95/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3573 - accuracy: 0.8472 - val_loss: 0.3910 - val_accuracy: 0.8327\n","Epoch 96/100\n","547/547 [==============================] - 2s 4ms/step - loss: 0.3570 - accuracy: 0.8496 - val_loss: 0.3929 - val_accuracy: 0.8321\n","Epoch 97/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3561 - accuracy: 0.8493 - val_loss: 0.3863 - val_accuracy: 0.8353\n","Epoch 98/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3544 - accuracy: 0.8491 - val_loss: 0.3905 - val_accuracy: 0.8324\n","Epoch 99/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3553 - accuracy: 0.8501 - val_loss: 0.3832 - val_accuracy: 0.8341\n","Epoch 100/100\n","547/547 [==============================] - 3s 5ms/step - loss: 0.3551 - accuracy: 0.8481 - val_loss: 0.3904 - val_accuracy: 0.8323\n"]}]},{"cell_type":"code","source":["## uncomment to see f1 score\n","\n","# pca_test_data = pca.transform(tXY[NumFeatures])\n","# y_test = tXY.Rev[50000:]\n","# y_pred = pd.DataFrame(m.predict(pca_test_data[50000:]))\n","\n","# y_pred = y_pred.round(0).astype(int)\n","\n","# from sklearn.metrics import f1_score\n","# f1_score(y_test, y_pred, average='micro')"],"metadata":{"id":"dhH1DbC5GSQl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657387583931,"user_tz":240,"elapsed":17820,"user":{"displayName":"Antoine Nguyen","userId":"04950359765811679258"}},"outputId":"d28cff1f-8f69-409a-94b4-f3497120ad92"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.84715"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["pca_test_data = pca.transform(vX)"],"metadata":{"id":"dfdwNRceGSLD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pY = pd.DataFrame(m.predict(pca_test_data), index=vX.index+1, columns=['Rev'])\n","pY.index.names = ['id']\n","ToCSV(pY.round(0).astype(int), 'batch_size_epoch_100')\n","tXY.Rev.value_counts()/len(tXY)     "],"metadata":{"id":"3i71_tHRGQK6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657386742849,"user_tz":240,"elapsed":2672,"user":{"displayName":"Antoine Nguyen","userId":"04950359765811679258"}},"outputId":"daebcdb3-fd50-461d-c42c-4eec89e2eadd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0    0.78\n","1.0    0.22\n","Name: Rev, dtype: float64"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["# **References:**"],"metadata":{"id":"pzBsjCvS_kEw"}},{"cell_type":"markdown","source":["1. Remember to cite your sources!\n"],"metadata":{"id":"2kr8Q-9T_nAb"}},{"cell_type":"markdown","source":["<font size=5>‚åõ</font> <strong><font color=orange size=5>Do not exceed competition's runtime limit!</font></strong>\n","\n","<hr color=red>\n"],"metadata":{"id":"DoF2GoB_QGw9"}},{"cell_type":"code","source":["#tmr.ShowTime()    # measure Colab's runtime. Do not remove. Keep as the last cell in your notebook."],"metadata":{"id":"bD1sdgYbNWQA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oUStTaN4uo_Z"},"source":["## üí°**Starter Ideas**"]},{"cell_type":"markdown","source":["**Model**\n","1. Tune model hyperparameters, batch size, optimizer, NN layers\n","\n","**Features**\n","1. Try to linear and non-linear feature normalization: shift/scale, log, divide features by features (investigate scatterplot matrix)\n","1. Try higher order feature interactions and polynomial features on a small subsample. Then identify key features or select key principal components. The final model can be trained on a larger or even full training sample. You can use [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) to reduce the feature set\n","1. Incorporate categorical features (appropriately encoded)\n","  1. E.g. you could replace codes (or groups of codes) with their frequencies, which may capture the implied \"distance\" or rarity between category levels.\n","  1. If encoding ordinal features with integers, should non-equidistant values be considered?\n","\n","**Training observations**\n","1. Try clustering methods to remove similar observations. You may also try dimension reduction methods (eg. PCA) on the transposed data matrix (if it has scaled numeric features).\n","1. Look for and deal with outliers or influential points in the training set\n","1. Deal with **imbalanced sample**: oversample smaller class, or undersample larger class, or provide observation weights or provide class weights, or seek a suitable loss function\n","1. Investigate distributions of features. Any missing values? Any zero values?\n","\n","**Predictions**\n","1. Evaluate predictions and focus on poorly predicted \"groups\":\n","  1. Strongest misclassifications. E.g. the model is very confident about the wrong label\n","  1. Evaluate predictions near decision boundaries.\n","\n","**EDA and Domain Expertise**\n","1. Do a thorough EDA: look for feature augmentations that result in linear decision boundaries between pairs of classes.\n","1. Learn about the domain: how should output relate to features? How do month or weekend impact users' buying activity?\n","  1. User Agent [&#127910;](https://www.youtube.com/results?search_query=user+agent+browser), Google Analytics [&#127910;](https://www.youtube.com/results?search_query=google+analytics), tracking online shopping intent [&#127910;](https://www.youtube.com/results?search_query=tacking+online+shopping+intent), [üìÑ](https://scholar.google.com/scholar?q=tracking+online+shopping+intent)"],"metadata":{"id":"q4QO-u3t8xAO"}}]}